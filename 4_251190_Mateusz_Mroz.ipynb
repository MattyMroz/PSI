{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a2qySbrhKlEn",
        "outputId": "a9fd0a59-de0d-4675-c218-dc466502f2e7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Pobieranie danych MNIST...\n",
            "Dane gotowe.\n",
            "Klasy, funkcje pomocnicze i dane MNIST gotowe.\n"
          ]
        }
      ],
      "source": [
        "# @title Definicje Klas i Funkcji Pomocniczych\n",
        "import numpy as np\n",
        "import urllib.request\n",
        "import zipfile\n",
        "import os\n",
        "import struct\n",
        "import time\n",
        "import ssl\n",
        "\n",
        "# Definicje Klas\n",
        "\n",
        "class Layer:\n",
        "    \"\"\"Reprezentuje warstwę w pełni połączoną (liniową) z obsługą batchy\"\"\"\n",
        "    def __init__(self, input_size, output_size):\n",
        "        # Zmiana inicjalizacji wag, aby dopasować do różnych aktywacji\n",
        "        self.weights = np.random.randn(input_size, output_size) * np.sqrt(2. / input_size)\n",
        "        self.bias = np.zeros((1, output_size))\n",
        "        self.input = None\n",
        "        self.weights_error = None\n",
        "        self.bias_error = None\n",
        "\n",
        "    def forward(self, input_data):\n",
        "        self.input = input_data\n",
        "        return self.input @ self.weights + self.bias\n",
        "\n",
        "    def backward(self, output_error):\n",
        "        self.weights_error = self.input.T @ output_error\n",
        "        self.bias_error = np.sum(output_error, axis=0, keepdims=True)\n",
        "        input_error = output_error @ self.weights.T\n",
        "        return input_error\n",
        "\n",
        "    def adjust(self, learning_rate):\n",
        "        self.weights -= learning_rate * self.weights_error\n",
        "        self.bias -= learning_rate * self.bias_error\n",
        "\n",
        "class Activation:\n",
        "    \"\"\"Reprezentuje warstwę aktywacji\"\"\"\n",
        "    def __init__(self, activation, activation_prime):\n",
        "        self.activation = activation\n",
        "        self.activation_prime = activation_prime\n",
        "        self.input = None\n",
        "        self.output = None\n",
        "\n",
        "    def forward(self, input_data):\n",
        "        self.input = input_data\n",
        "        self.output = self.activation(self.input)\n",
        "        return self.output\n",
        "\n",
        "    def backward(self, output_error):\n",
        "        return output_error * self.activation_prime(self.input)\n",
        "\n",
        "    def adjust(self, learning_rate):\n",
        "        pass\n",
        "\n",
        "class Dropout:\n",
        "    \"\"\"Warstwa Dropout\"\"\"\n",
        "    def __init__(self, rate):\n",
        "        self.rate = rate\n",
        "        self.mask = None\n",
        "\n",
        "    def forward(self, input_data, training=True):\n",
        "        if training:\n",
        "            # Tworzymy maskę i skalujemy\n",
        "            self.mask = np.random.binomial(1, 1 - self.rate, size=input_data.shape) / (1 - self.rate)\n",
        "            return input_data * self.mask\n",
        "        else:\n",
        "            return input_data\n",
        "\n",
        "    def backward(self, output_error):\n",
        "        # Propagujemy błąd tylko przez aktywne neurony\n",
        "        return output_error * self.mask\n",
        "\n",
        "    def adjust(self, learning_rate):\n",
        "        pass\n",
        "\n",
        "\n",
        "# Funkcje Aktywacji\n",
        "\n",
        "def relu(x):\n",
        "    return np.maximum(0, x)\n",
        "\n",
        "def relu_prime(x):\n",
        "    return (x > 0).astype(float)\n",
        "\n",
        "def sigmoid(x):\n",
        "    return 1 / (1 + np.exp(-np.clip(x, -500, 500)))\n",
        "\n",
        "def sigmoid_prime(x):\n",
        "    s = sigmoid(x)\n",
        "    return s * (1 - s)\n",
        "\n",
        "def tanh(x):\n",
        "    return np.tanh(x)\n",
        "\n",
        "def tanh_prime(x):\n",
        "    return 1 - np.tanh(x)**2\n",
        "\n",
        "def softmax(x):\n",
        "    exps = np.exp(x - np.max(x, axis=1, keepdims=True))\n",
        "    return exps / np.sum(exps, axis=1, keepdims=True)\n",
        "\n",
        "def softmax_prime(x):\n",
        "    return 1\n",
        "\n",
        "# Funkcje do ładowania danych MNIST\n",
        "def _download_data(url, save_path='.'):\n",
        "    zip_path = os.path.join(save_path, 'MNIST_ORG.zip')\n",
        "    data_dir = os.path.join(save_path, 'mnist_data')\n",
        "    if not os.path.exists(data_dir):\n",
        "        print(\"Pobieranie danych MNIST...\")\n",
        "        ssl_context = ssl._create_unverified_context()\n",
        "        with urllib.request.urlopen(url, context=ssl_context) as response, open(zip_path, 'wb') as out_file:\n",
        "            out_file.write(response.read())\n",
        "        with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "            zip_ref.extractall(data_dir)\n",
        "        os.remove(zip_path)\n",
        "        print(\"Dane gotowe.\")\n",
        "    return data_dir\n",
        "\n",
        "def _load_mnist(data_dir):\n",
        "    def load_images(filename):\n",
        "        with open(filename, 'rb') as f:\n",
        "            _, num, rows, cols = struct.unpack('>IIII', f.read(16))\n",
        "            return np.fromfile(f, dtype=np.uint8).reshape(num, rows * cols).astype(np.float32) / 255.0\n",
        "    def load_labels(filename):\n",
        "        with open(filename, 'rb') as f:\n",
        "            _, num = struct.unpack('>II', f.read(8))\n",
        "            labels = np.fromfile(f, dtype=np.uint8)\n",
        "            one_hot = np.zeros((num, 10))\n",
        "            one_hot[np.arange(num), labels] = 1\n",
        "            return one_hot, labels\n",
        "\n",
        "    X_train = load_images(os.path.join(data_dir, 'train-images.idx3-ubyte'))\n",
        "    Y_train, y_train_labels = load_labels(os.path.join(data_dir, 'train-labels.idx1-ubyte'))\n",
        "    X_test = load_images(os.path.join(data_dir, 't10k-images.idx3-ubyte'))\n",
        "    _, y_test_labels = load_labels(os.path.join(data_dir, 't10k-labels.idx1-ubyte'))\n",
        "    return X_train, Y_train, y_train_labels, X_test, y_test_labels\n",
        "\n",
        "# Wczytanie danych raz na początku\n",
        "data_dir = _download_data('http://pduch.kis.p.lodz.pl/PSI/MNIST_ORG.zip')\n",
        "X_train_all, Y_train_all, y_train_labels_all, X_test_all, y_test_labels_all = _load_mnist(data_dir)\n",
        "\n",
        "print(\"Klasy, funkcje pomocnicze i dane MNIST gotowe.\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title L4 - Zadanie 1: Implementacja Dropout\n",
        "# section: main_execution (Zadanie 4.3.1)\n",
        "def run_experiment_dropout(hidden_size, train_size, epochs, alpha):\n",
        "    print(\"\\n\" + \"=\"*80)\n",
        "    print(f\"START EKSPERYMENTU (Dropout): Hidden: {hidden_size}, Train: {train_size}\")\n",
        "    print(f\"Params: alpha={alpha}, epochs={epochs}, weights=<-0.1, 0.1>\")\n",
        "    print(\"=\"*80)\n",
        "\n",
        "    # Przygotowanie danych\n",
        "    X_train = X_train_all[:train_size]\n",
        "    Y_train = Y_train_all[:train_size]\n",
        "    y_train_labels = y_train_labels_all[:train_size]\n",
        "    X_test = X_test_all\n",
        "    y_test_labels = y_test_labels_all\n",
        "\n",
        "    # Budowa sieci\n",
        "    network = [\n",
        "        Layer(784, hidden_size),\n",
        "        Activation(relu, relu_prime),\n",
        "        Dropout(0.5),\n",
        "        Layer(hidden_size, 10)\n",
        "    ]\n",
        "    network[0].weights = np.random.uniform(-0.1, 0.1, (784, hidden_size))\n",
        "    network[3].weights = np.random.uniform(-0.1, 0.1, (hidden_size, 10))\n",
        "\n",
        "    start_time = time.time()\n",
        "    for epoch in range(epochs):\n",
        "        total_error = 0\n",
        "        train_correct = 0\n",
        "        indices = np.arange(train_size)\n",
        "        np.random.shuffle(indices)\n",
        "\n",
        "        for i in indices:\n",
        "            x = X_train[i:i+1]\n",
        "            y = Y_train[i:i+1]\n",
        "\n",
        "            # Forward pass (z włączonym Dropout)\n",
        "            output = x\n",
        "            for layer in network:\n",
        "                if isinstance(layer, Dropout):\n",
        "                    output = layer.forward(output, training=True)\n",
        "                else:\n",
        "                    output = layer.forward(output)\n",
        "\n",
        "            # Zbieranie statystyk\n",
        "            total_error += np.sum((output - y)**2)\n",
        "            if np.argmax(output) == y_train_labels[i]:\n",
        "                train_correct += 1\n",
        "\n",
        "            # Obliczanie błędu do propagacji\n",
        "            error = 2 * (output - y) / y.size\n",
        "\n",
        "            # Backward pass\n",
        "            for layer in reversed(network):\n",
        "                error = layer.backward(error)\n",
        "\n",
        "            # Aktualizacja wag\n",
        "            for layer in network:\n",
        "                layer.adjust(alpha)\n",
        "\n",
        "        # Ewaluacja i logowanie\n",
        "        if epoch % 10 == 0 or epoch == epochs - 1:\n",
        "            test_correct = 0\n",
        "            for i in range(len(X_test)):\n",
        "                x_test = X_test[i:i+1]\n",
        "                output = x_test\n",
        "                # Forward pass (z wyłączonym Dropout)\n",
        "                for layer in network:\n",
        "                    if isinstance(layer, Dropout):\n",
        "                        output = layer.forward(output, training=False)\n",
        "                    else:\n",
        "                        output = layer.forward(output)\n",
        "                if np.argmax(output) == y_test_labels[i]:\n",
        "                    test_correct += 1\n",
        "\n",
        "            avg_error = total_error / train_size\n",
        "            train_accuracy = (train_correct / train_size) * 100\n",
        "            test_accuracy = (test_correct / len(X_test)) * 100\n",
        "\n",
        "            print(f\"Iter: {epoch:3d} Error: {avg_error:.6f} Train Acc: {train_accuracy:.2f}% Test Acc: {test_accuracy:.2f}%\")\n",
        "\n",
        "    print(f\"Trening zakończony w {time.time() - start_time:.2f}s\")\n",
        "\n",
        "# Uruchomienie eksperymentów z zadania\n",
        "run_experiment_dropout(hidden_size=40, train_size=1000, epochs=350, alpha=0.005)\n",
        "run_experiment_dropout(hidden_size=100, train_size=10000, epochs=350, alpha=0.005)\n",
        "run_experiment_dropout(hidden_size=100, train_size=60000, epochs=350, alpha=0.005)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xk_S4QB4MwLk",
        "outputId": "299e0710-ed04-4910-b5e9-38f0d59eb178",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "START EKSPERYMENTU (Dropout): Hidden: 40, Train: 1000\n",
            "Params: alpha=0.005, epochs=350, weights=<-0.1, 0.1>\n",
            "================================================================================\n",
            "Iter:   0 Error: 0.990782 Train Acc: 15.50% Test Acc: 33.72%\n",
            "Iter:  10 Error: 0.623250 Train Acc: 59.00% Test Acc: 67.72%\n",
            "Iter:  20 Error: 0.512055 Train Acc: 67.50% Test Acc: 75.23%\n",
            "Iter:  30 Error: 0.467602 Train Acc: 72.70% Test Acc: 79.65%\n",
            "Iter:  40 Error: 0.431993 Train Acc: 76.20% Test Acc: 81.36%\n",
            "Iter:  50 Error: 0.399666 Train Acc: 77.80% Test Acc: 82.71%\n",
            "Iter:  60 Error: 0.389508 Train Acc: 79.60% Test Acc: 83.48%\n",
            "Iter:  70 Error: 0.371970 Train Acc: 81.20% Test Acc: 84.56%\n",
            "Iter:  80 Error: 0.364072 Train Acc: 82.70% Test Acc: 84.90%\n",
            "Iter:  90 Error: 0.342050 Train Acc: 85.00% Test Acc: 85.07%\n",
            "Iter: 100 Error: 0.338579 Train Acc: 84.40% Test Acc: 85.10%\n",
            "Iter: 110 Error: 0.329628 Train Acc: 86.00% Test Acc: 85.36%\n",
            "Iter: 120 Error: 0.309416 Train Acc: 87.00% Test Acc: 85.61%\n",
            "Iter: 130 Error: 0.324329 Train Acc: 84.20% Test Acc: 85.68%\n",
            "Iter: 140 Error: 0.306630 Train Acc: 86.40% Test Acc: 85.87%\n",
            "Iter: 150 Error: 0.308856 Train Acc: 85.40% Test Acc: 85.80%\n",
            "Iter: 160 Error: 0.297092 Train Acc: 88.40% Test Acc: 85.75%\n",
            "Iter: 170 Error: 0.288207 Train Acc: 87.90% Test Acc: 85.95%\n",
            "Iter: 180 Error: 0.293636 Train Acc: 87.40% Test Acc: 85.83%\n",
            "Iter: 190 Error: 0.299289 Train Acc: 87.00% Test Acc: 85.64%\n",
            "Iter: 200 Error: 0.283315 Train Acc: 88.10% Test Acc: 85.62%\n",
            "Iter: 210 Error: 0.264179 Train Acc: 88.70% Test Acc: 85.48%\n",
            "Iter: 220 Error: 0.295267 Train Acc: 86.30% Test Acc: 85.80%\n",
            "Iter: 230 Error: 0.277301 Train Acc: 88.60% Test Acc: 85.73%\n",
            "Iter: 240 Error: 0.283931 Train Acc: 88.90% Test Acc: 85.81%\n",
            "Iter: 250 Error: 0.275472 Train Acc: 88.00% Test Acc: 85.61%\n",
            "Iter: 260 Error: 0.256208 Train Acc: 90.50% Test Acc: 85.60%\n",
            "Iter: 270 Error: 0.268147 Train Acc: 88.70% Test Acc: 85.04%\n",
            "Iter: 280 Error: 0.249533 Train Acc: 90.30% Test Acc: 85.30%\n",
            "Iter: 290 Error: 0.286654 Train Acc: 86.40% Test Acc: 85.28%\n",
            "Iter: 300 Error: 0.253245 Train Acc: 89.70% Test Acc: 85.27%\n",
            "Iter: 310 Error: 0.264818 Train Acc: 89.40% Test Acc: 85.15%\n",
            "Iter: 320 Error: 0.257966 Train Acc: 89.10% Test Acc: 85.15%\n",
            "Iter: 330 Error: 0.257242 Train Acc: 88.90% Test Acc: 85.69%\n",
            "Iter: 340 Error: 0.247849 Train Acc: 89.30% Test Acc: 85.77%\n",
            "Iter: 349 Error: 0.247693 Train Acc: 90.80% Test Acc: 85.59%\n",
            "Trening zakończony w 83.33s\n",
            "\n",
            "================================================================================\n",
            "START EKSPERYMENTU (Dropout): Hidden: 100, Train: 10000\n",
            "Params: alpha=0.005, epochs=350, weights=<-0.1, 0.1>\n",
            "================================================================================\n",
            "Iter:   0 Error: 0.724007 Train Acc: 53.31% Test Acc: 78.56%\n",
            "Iter:  10 Error: 0.314527 Train Acc: 86.98% Test Acc: 90.77%\n",
            "Iter:  20 Error: 0.281073 Train Acc: 89.32% Test Acc: 91.89%\n",
            "Iter:  30 Error: 0.259648 Train Acc: 90.42% Test Acc: 92.40%\n",
            "Iter:  40 Error: 0.253303 Train Acc: 91.32% Test Acc: 92.95%\n",
            "Iter:  50 Error: 0.241225 Train Acc: 92.41% Test Acc: 92.87%\n",
            "Iter:  60 Error: 0.234037 Train Acc: 92.58% Test Acc: 93.29%\n",
            "Iter:  70 Error: 0.231292 Train Acc: 93.08% Test Acc: 93.43%\n",
            "Iter:  80 Error: 0.226044 Train Acc: 93.42% Test Acc: 93.52%\n",
            "Iter:  90 Error: 0.219798 Train Acc: 93.43% Test Acc: 93.52%\n",
            "Iter: 100 Error: 0.217729 Train Acc: 93.79% Test Acc: 93.55%\n",
            "Iter: 110 Error: 0.216822 Train Acc: 93.87% Test Acc: 93.66%\n",
            "Iter: 120 Error: 0.212757 Train Acc: 94.11% Test Acc: 93.74%\n",
            "Iter: 130 Error: 0.212854 Train Acc: 93.89% Test Acc: 93.67%\n",
            "Iter: 140 Error: 0.211473 Train Acc: 94.26% Test Acc: 93.91%\n",
            "Iter: 150 Error: 0.207517 Train Acc: 94.54% Test Acc: 93.71%\n",
            "Iter: 160 Error: 0.204048 Train Acc: 94.71% Test Acc: 93.97%\n",
            "Iter: 170 Error: 0.200958 Train Acc: 94.82% Test Acc: 93.85%\n",
            "Iter: 180 Error: 0.204120 Train Acc: 94.45% Test Acc: 93.93%\n",
            "Iter: 190 Error: 0.200333 Train Acc: 95.01% Test Acc: 94.03%\n",
            "Iter: 200 Error: 0.199340 Train Acc: 94.88% Test Acc: 93.94%\n",
            "Iter: 210 Error: 0.197690 Train Acc: 95.25% Test Acc: 93.94%\n",
            "Iter: 220 Error: 0.196204 Train Acc: 95.17% Test Acc: 94.00%\n",
            "Iter: 230 Error: 0.199448 Train Acc: 95.23% Test Acc: 94.05%\n",
            "Iter: 240 Error: 0.195062 Train Acc: 95.30% Test Acc: 94.17%\n",
            "Iter: 250 Error: 0.196191 Train Acc: 95.01% Test Acc: 94.21%\n",
            "Iter: 260 Error: 0.193609 Train Acc: 95.44% Test Acc: 93.93%\n",
            "Iter: 270 Error: 0.188520 Train Acc: 95.76% Test Acc: 93.95%\n",
            "Iter: 280 Error: 0.190086 Train Acc: 95.53% Test Acc: 94.16%\n",
            "Iter: 290 Error: 0.194907 Train Acc: 95.62% Test Acc: 94.07%\n",
            "Iter: 300 Error: 0.190293 Train Acc: 95.72% Test Acc: 94.16%\n",
            "Iter: 310 Error: 0.190008 Train Acc: 95.65% Test Acc: 93.87%\n",
            "Iter: 320 Error: 0.186910 Train Acc: 95.87% Test Acc: 93.87%\n",
            "Iter: 330 Error: 0.187059 Train Acc: 95.84% Test Acc: 94.16%\n",
            "Iter: 340 Error: 0.186324 Train Acc: 95.93% Test Acc: 94.11%\n",
            "Iter: 349 Error: 0.187725 Train Acc: 95.87% Test Acc: 94.17%\n",
            "Trening zakończony w 1617.28s\n",
            "\n",
            "================================================================================\n",
            "START EKSPERYMENTU (Dropout): Hidden: 100, Train: 60000\n",
            "Params: alpha=0.005, epochs=350, weights=<-0.1, 0.1>\n",
            "================================================================================\n",
            "Iter:   0 Error: 0.486763 Train Acc: 73.25% Test Acc: 89.58%\n",
            "Iter:  10 Error: 0.260340 Train Acc: 90.73% Test Acc: 93.95%\n",
            "Iter:  20 Error: 0.241518 Train Acc: 91.75% Test Acc: 94.71%\n",
            "Iter:  30 Error: 0.231957 Train Acc: 92.31% Test Acc: 94.93%\n",
            "Iter:  40 Error: 0.227559 Train Acc: 92.73% Test Acc: 95.26%\n",
            "Iter:  50 Error: 0.224383 Train Acc: 92.99% Test Acc: 95.41%\n",
            "Iter:  60 Error: 0.221221 Train Acc: 92.97% Test Acc: 95.44%\n",
            "Iter:  70 Error: 0.218277 Train Acc: 93.39% Test Acc: 95.52%\n",
            "Iter:  80 Error: 0.217763 Train Acc: 93.33% Test Acc: 95.51%\n",
            "Iter:  90 Error: 0.215456 Train Acc: 93.42% Test Acc: 95.67%\n",
            "Iter: 100 Error: 0.213717 Train Acc: 93.61% Test Acc: 95.60%\n",
            "Iter: 110 Error: 0.212535 Train Acc: 93.62% Test Acc: 95.65%\n",
            "Iter: 120 Error: 0.211477 Train Acc: 93.74% Test Acc: 95.80%\n",
            "Iter: 130 Error: 0.209080 Train Acc: 93.92% Test Acc: 95.70%\n",
            "Iter: 140 Error: 0.210018 Train Acc: 93.89% Test Acc: 95.77%\n",
            "Iter: 150 Error: 0.209187 Train Acc: 93.94% Test Acc: 95.72%\n",
            "Iter: 160 Error: 0.208607 Train Acc: 93.98% Test Acc: 95.76%\n",
            "Iter: 170 Error: 0.207326 Train Acc: 93.98% Test Acc: 95.85%\n",
            "Iter: 180 Error: 0.208133 Train Acc: 93.99% Test Acc: 95.86%\n",
            "Iter: 190 Error: 0.205803 Train Acc: 94.09% Test Acc: 95.78%\n",
            "Iter: 200 Error: 0.207054 Train Acc: 93.98% Test Acc: 96.02%\n",
            "Iter: 210 Error: 0.206207 Train Acc: 94.10% Test Acc: 95.89%\n",
            "Iter: 220 Error: 0.205591 Train Acc: 94.22% Test Acc: 95.90%\n",
            "Iter: 230 Error: 0.205504 Train Acc: 94.14% Test Acc: 95.93%\n",
            "Iter: 240 Error: 0.204740 Train Acc: 94.13% Test Acc: 95.93%\n",
            "Iter: 250 Error: 0.204703 Train Acc: 94.15% Test Acc: 95.94%\n",
            "Iter: 260 Error: 0.204431 Train Acc: 94.25% Test Acc: 95.79%\n",
            "Iter: 270 Error: 0.203245 Train Acc: 94.21% Test Acc: 95.93%\n",
            "Iter: 280 Error: 0.203007 Train Acc: 94.29% Test Acc: 95.79%\n",
            "Iter: 290 Error: 0.203465 Train Acc: 94.34% Test Acc: 95.89%\n",
            "Iter: 300 Error: 0.203268 Train Acc: 94.25% Test Acc: 95.87%\n",
            "Iter: 310 Error: 0.202662 Train Acc: 94.31% Test Acc: 95.91%\n",
            "Iter: 320 Error: 0.203015 Train Acc: 94.32% Test Acc: 95.87%\n",
            "Iter: 330 Error: 0.202811 Train Acc: 94.27% Test Acc: 95.94%\n",
            "Iter: 340 Error: 0.202524 Train Acc: 94.29% Test Acc: 95.85%\n",
            "Iter: 349 Error: 0.201957 Train Acc: 94.29% Test Acc: 95.86%\n",
            "Trening zakończony w 9665.49s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title L4 - Zadanie 2: Implementacja Mini-Batch\n",
        "# section: main_execution (Zadanie 4.3.2)\n",
        "def run_experiment_minibatch(hidden_size, train_size, epochs, alpha, batch_size):\n",
        "    print(\"\\n\" + \"=\"*80)\n",
        "    print(f\"START EKSPERYMENTU (Mini-Batch): Hidden: {hidden_size}, Train: {train_size}, Batch: {batch_size}\")\n",
        "    print(f\"Params: alpha={alpha}, epochs={epochs}, weights=<-0.1, 0.1>\")\n",
        "    print(\"=\"*80)\n",
        "\n",
        "    # Przygotowanie danych\n",
        "    X_train = X_train_all[:train_size]\n",
        "    Y_train = Y_train_all[:train_size]\n",
        "    y_train_labels = y_train_labels_all[:train_size]\n",
        "    X_test = X_test_all\n",
        "    y_test_labels = y_test_labels_all\n",
        "\n",
        "    # Budowa sieci\n",
        "    network = [\n",
        "        Layer(784, hidden_size),\n",
        "        Activation(relu, relu_prime),\n",
        "        Dropout(0.5),\n",
        "        Layer(hidden_size, 10)\n",
        "    ]\n",
        "    network[0].weights = np.random.uniform(-0.1, 0.1, (784, hidden_size))\n",
        "    network[3].weights = np.random.uniform(-0.1, 0.1, (hidden_size, 10))\n",
        "\n",
        "    start_time = time.time()\n",
        "    for epoch in range(epochs):\n",
        "        total_error = 0\n",
        "        indices = np.arange(train_size)\n",
        "        np.random.shuffle(indices)\n",
        "\n",
        "        for i in range(0, train_size, batch_size):\n",
        "            batch_indices = indices[i:i+batch_size]\n",
        "            x_batch = X_train[batch_indices]\n",
        "            y_batch = Y_train[batch_indices]\n",
        "\n",
        "            # Forward pass\n",
        "            output = x_batch\n",
        "            for layer in network:\n",
        "                if isinstance(layer, Dropout):\n",
        "                    output = layer.forward(output, training=True)\n",
        "                else:\n",
        "                    output = layer.forward(output)\n",
        "\n",
        "            total_error += np.sum((output - y_batch)**2)\n",
        "\n",
        "            # Obliczanie błędu do propagacji\n",
        "            error = 2 * (output - y_batch) / y_batch.size\n",
        "\n",
        "            # Backward pass\n",
        "            for layer in reversed(network):\n",
        "                error = layer.backward(error)\n",
        "\n",
        "            # Aktualizacja wag\n",
        "            for layer in network:\n",
        "                layer.adjust(alpha)\n",
        "\n",
        "        # Ewaluacja i logowanie\n",
        "        if epoch % 10 == 0 or epoch == epochs - 1:\n",
        "            # Ewaluacja na zbiorze treningowym (z wyłączonym dropout)\n",
        "            train_correct = 0\n",
        "            for j in range(0, train_size, batch_size):\n",
        "                x_train_batch = X_train[j:j+batch_size]\n",
        "                y_train_labels_batch = y_train_labels[j:j+batch_size]\n",
        "                output = x_train_batch\n",
        "                for layer in network:\n",
        "                    if isinstance(layer, Dropout):\n",
        "                        output = layer.forward(output, training=False)\n",
        "                    else:\n",
        "                        output = layer.forward(output)\n",
        "                train_correct += np.sum(np.argmax(output, axis=1) == y_train_labels_batch)\n",
        "\n",
        "            # Ewaluacja na zbiorze testowym\n",
        "            test_correct = 0\n",
        "            for j in range(0, len(X_test), batch_size):\n",
        "                x_test_batch = X_test[j:j+batch_size]\n",
        "                y_test_labels_batch = y_test_labels[j:j+batch_size]\n",
        "                output = x_test_batch\n",
        "                for layer in network:\n",
        "                    if isinstance(layer, Dropout):\n",
        "                        output = layer.forward(output, training=False)\n",
        "                    else:\n",
        "                        output = layer.forward(output)\n",
        "                test_correct += np.sum(np.argmax(output, axis=1) == y_test_labels_batch)\n",
        "\n",
        "            avg_error = total_error / train_size\n",
        "            train_accuracy = (train_correct / train_size) * 100\n",
        "            test_accuracy = (test_correct / len(X_test)) * 100\n",
        "\n",
        "            print(f\"Iter: {epoch:3d} Error: {avg_error:.6f} Train Acc: {train_accuracy:.2f}% Test Acc: {test_accuracy:.2f}%\")\n",
        "\n",
        "    print(f\"Trening zakończony w {time.time() - start_time:.2f}s\")\n",
        "\n",
        "# Uruchomienie eksperymentów z zadania\n",
        "run_experiment_minibatch(hidden_size=40, train_size=1000, epochs=350, alpha=0.1, batch_size=100)\n",
        "run_experiment_minibatch(hidden_size=100, train_size=10000, epochs=350, alpha=0.1, batch_size=100)\n",
        "run_experiment_minibatch(hidden_size=100, train_size=60000, epochs=350, alpha=0.1, batch_size=100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iNVUMSR2PhFc",
        "outputId": "b4bc34f5-51ef-4878-e8b7-510c27dfd15c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "START EKSPERYMENTU (Mini-Batch): Hidden: 40, Train: 1000, Batch: 100\n",
            "Params: alpha=0.1, epochs=350, weights=<-0.1, 0.1>\n",
            "================================================================================\n",
            "Iter:   0 Error: 1.198729 Train Acc: 13.20% Test Acc: 12.76%\n",
            "Iter:  10 Error: 0.837676 Train Acc: 49.40% Test Acc: 45.18%\n",
            "Iter:  20 Error: 0.767793 Train Acc: 64.50% Test Acc: 57.81%\n",
            "Iter:  30 Error: 0.712162 Train Acc: 69.00% Test Acc: 63.10%\n",
            "Iter:  40 Error: 0.675672 Train Acc: 73.40% Test Acc: 66.97%\n",
            "Iter:  50 Error: 0.632124 Train Acc: 75.20% Test Acc: 69.30%\n",
            "Iter:  60 Error: 0.599789 Train Acc: 77.30% Test Acc: 71.14%\n",
            "Iter:  70 Error: 0.583847 Train Acc: 78.40% Test Acc: 72.77%\n",
            "Iter:  80 Error: 0.557539 Train Acc: 79.90% Test Acc: 73.58%\n",
            "Iter:  90 Error: 0.541881 Train Acc: 81.30% Test Acc: 74.66%\n",
            "Iter: 100 Error: 0.525972 Train Acc: 82.90% Test Acc: 75.22%\n",
            "Iter: 110 Error: 0.504870 Train Acc: 83.60% Test Acc: 76.15%\n",
            "Iter: 120 Error: 0.514933 Train Acc: 84.40% Test Acc: 77.14%\n",
            "Iter: 130 Error: 0.478173 Train Acc: 86.00% Test Acc: 78.01%\n",
            "Iter: 140 Error: 0.470652 Train Acc: 86.70% Test Acc: 78.60%\n",
            "Iter: 150 Error: 0.459487 Train Acc: 87.70% Test Acc: 79.48%\n",
            "Iter: 160 Error: 0.450827 Train Acc: 88.00% Test Acc: 80.21%\n",
            "Iter: 170 Error: 0.464615 Train Acc: 88.30% Test Acc: 80.71%\n",
            "Iter: 180 Error: 0.446348 Train Acc: 88.80% Test Acc: 81.14%\n",
            "Iter: 190 Error: 0.425811 Train Acc: 89.60% Test Acc: 81.47%\n",
            "Iter: 200 Error: 0.421700 Train Acc: 90.00% Test Acc: 81.99%\n",
            "Iter: 210 Error: 0.412829 Train Acc: 90.40% Test Acc: 82.40%\n",
            "Iter: 220 Error: 0.403440 Train Acc: 90.80% Test Acc: 82.65%\n",
            "Iter: 230 Error: 0.410060 Train Acc: 91.00% Test Acc: 82.64%\n",
            "Iter: 240 Error: 0.411028 Train Acc: 91.40% Test Acc: 82.89%\n",
            "Iter: 250 Error: 0.402312 Train Acc: 92.30% Test Acc: 83.20%\n",
            "Iter: 260 Error: 0.387968 Train Acc: 92.70% Test Acc: 83.42%\n",
            "Iter: 270 Error: 0.384414 Train Acc: 93.20% Test Acc: 83.58%\n",
            "Iter: 280 Error: 0.391355 Train Acc: 93.10% Test Acc: 83.76%\n",
            "Iter: 290 Error: 0.369176 Train Acc: 93.40% Test Acc: 83.49%\n",
            "Iter: 300 Error: 0.365481 Train Acc: 93.60% Test Acc: 83.80%\n",
            "Iter: 310 Error: 0.358896 Train Acc: 94.10% Test Acc: 84.00%\n",
            "Iter: 320 Error: 0.375469 Train Acc: 94.30% Test Acc: 84.17%\n",
            "Iter: 330 Error: 0.370032 Train Acc: 94.50% Test Acc: 84.16%\n",
            "Iter: 340 Error: 0.368462 Train Acc: 94.80% Test Acc: 84.14%\n",
            "Iter: 349 Error: 0.366547 Train Acc: 94.90% Test Acc: 84.31%\n",
            "Trening zakończony w 7.45s\n",
            "\n",
            "================================================================================\n",
            "START EKSPERYMENTU (Mini-Batch): Hidden: 100, Train: 10000, Batch: 100\n",
            "Params: alpha=0.1, epochs=350, weights=<-0.1, 0.1>\n",
            "================================================================================\n",
            "Iter:   0 Error: 0.969067 Train Acc: 59.19% Test Acc: 59.02%\n",
            "Iter:  10 Error: 0.475052 Train Acc: 85.66% Test Acc: 84.67%\n",
            "Iter:  20 Error: 0.393379 Train Acc: 88.78% Test Acc: 88.06%\n",
            "Iter:  30 Error: 0.354747 Train Acc: 90.39% Test Acc: 89.26%\n",
            "Iter:  40 Error: 0.331721 Train Acc: 91.25% Test Acc: 90.04%\n",
            "Iter:  50 Error: 0.317522 Train Acc: 91.68% Test Acc: 90.57%\n",
            "Iter:  60 Error: 0.311684 Train Acc: 92.20% Test Acc: 91.05%\n",
            "Iter:  70 Error: 0.297237 Train Acc: 92.68% Test Acc: 91.21%\n",
            "Iter:  80 Error: 0.290850 Train Acc: 93.00% Test Acc: 91.49%\n",
            "Iter:  90 Error: 0.285277 Train Acc: 93.15% Test Acc: 91.53%\n",
            "Iter: 100 Error: 0.279830 Train Acc: 93.40% Test Acc: 91.59%\n",
            "Iter: 110 Error: 0.275554 Train Acc: 93.56% Test Acc: 91.98%\n",
            "Iter: 120 Error: 0.270722 Train Acc: 93.64% Test Acc: 91.98%\n",
            "Iter: 130 Error: 0.270949 Train Acc: 93.94% Test Acc: 92.07%\n",
            "Iter: 140 Error: 0.264908 Train Acc: 94.09% Test Acc: 92.09%\n",
            "Iter: 150 Error: 0.261349 Train Acc: 94.18% Test Acc: 92.22%\n",
            "Iter: 160 Error: 0.261222 Train Acc: 94.25% Test Acc: 92.37%\n",
            "Iter: 170 Error: 0.256002 Train Acc: 94.58% Test Acc: 92.34%\n",
            "Iter: 180 Error: 0.258239 Train Acc: 94.64% Test Acc: 92.48%\n",
            "Iter: 190 Error: 0.253836 Train Acc: 94.77% Test Acc: 92.51%\n",
            "Iter: 200 Error: 0.252450 Train Acc: 94.86% Test Acc: 92.54%\n",
            "Iter: 210 Error: 0.244239 Train Acc: 94.92% Test Acc: 92.59%\n",
            "Iter: 220 Error: 0.243722 Train Acc: 95.13% Test Acc: 92.61%\n",
            "Iter: 230 Error: 0.246234 Train Acc: 95.17% Test Acc: 92.75%\n",
            "Iter: 240 Error: 0.241185 Train Acc: 95.27% Test Acc: 92.80%\n",
            "Iter: 250 Error: 0.243254 Train Acc: 95.41% Test Acc: 92.91%\n",
            "Iter: 260 Error: 0.238941 Train Acc: 95.46% Test Acc: 92.85%\n",
            "Iter: 270 Error: 0.236270 Train Acc: 95.58% Test Acc: 92.97%\n",
            "Iter: 280 Error: 0.234049 Train Acc: 95.62% Test Acc: 93.05%\n",
            "Iter: 290 Error: 0.237500 Train Acc: 95.68% Test Acc: 93.08%\n",
            "Iter: 300 Error: 0.233811 Train Acc: 95.84% Test Acc: 93.05%\n",
            "Iter: 310 Error: 0.231986 Train Acc: 95.91% Test Acc: 93.10%\n",
            "Iter: 320 Error: 0.232435 Train Acc: 95.95% Test Acc: 93.17%\n",
            "Iter: 330 Error: 0.228321 Train Acc: 96.03% Test Acc: 93.17%\n",
            "Iter: 340 Error: 0.226831 Train Acc: 96.19% Test Acc: 93.16%\n",
            "Iter: 349 Error: 0.229977 Train Acc: 96.12% Test Acc: 93.17%\n",
            "Trening zakończony w 135.82s\n",
            "\n",
            "================================================================================\n",
            "START EKSPERYMENTU (Mini-Batch): Hidden: 100, Train: 60000, Batch: 100\n",
            "Params: alpha=0.1, epochs=350, weights=<-0.1, 0.1>\n",
            "================================================================================\n",
            "Iter:   0 Error: 0.710445 Train Acc: 80.02% Test Acc: 81.02%\n",
            "Iter:  10 Error: 0.314389 Train Acc: 91.44% Test Acc: 91.82%\n",
            "Iter:  20 Error: 0.283420 Train Acc: 92.69% Test Acc: 92.82%\n",
            "Iter:  30 Error: 0.267587 Train Acc: 93.33% Test Acc: 93.34%\n",
            "Iter:  40 Error: 0.260547 Train Acc: 93.70% Test Acc: 93.73%\n",
            "Iter:  50 Error: 0.252573 Train Acc: 94.08% Test Acc: 94.03%\n",
            "Iter:  60 Error: 0.248522 Train Acc: 94.33% Test Acc: 94.15%\n",
            "Iter:  70 Error: 0.243696 Train Acc: 94.54% Test Acc: 94.34%\n",
            "Iter:  80 Error: 0.243389 Train Acc: 94.73% Test Acc: 94.60%\n",
            "Iter:  90 Error: 0.238575 Train Acc: 94.89% Test Acc: 94.66%\n",
            "Iter: 100 Error: 0.235112 Train Acc: 95.05% Test Acc: 94.80%\n",
            "Iter: 110 Error: 0.232625 Train Acc: 95.19% Test Acc: 94.93%\n",
            "Iter: 120 Error: 0.233254 Train Acc: 95.25% Test Acc: 94.97%\n",
            "Iter: 130 Error: 0.230191 Train Acc: 95.33% Test Acc: 95.03%\n",
            "Iter: 140 Error: 0.228258 Train Acc: 95.38% Test Acc: 95.04%\n",
            "Iter: 150 Error: 0.228431 Train Acc: 95.47% Test Acc: 95.11%\n",
            "Iter: 160 Error: 0.225376 Train Acc: 95.54% Test Acc: 95.15%\n",
            "Iter: 170 Error: 0.224825 Train Acc: 95.64% Test Acc: 95.17%\n",
            "Iter: 180 Error: 0.224351 Train Acc: 95.69% Test Acc: 95.27%\n",
            "Iter: 190 Error: 0.223654 Train Acc: 95.68% Test Acc: 95.25%\n",
            "Iter: 200 Error: 0.221714 Train Acc: 95.77% Test Acc: 95.35%\n",
            "Iter: 210 Error: 0.219433 Train Acc: 95.78% Test Acc: 95.37%\n",
            "Iter: 220 Error: 0.220505 Train Acc: 95.84% Test Acc: 95.25%\n",
            "Iter: 230 Error: 0.219117 Train Acc: 95.96% Test Acc: 95.45%\n",
            "Iter: 240 Error: 0.219636 Train Acc: 95.98% Test Acc: 95.43%\n",
            "Iter: 250 Error: 0.219094 Train Acc: 95.99% Test Acc: 95.46%\n",
            "Iter: 260 Error: 0.217671 Train Acc: 96.02% Test Acc: 95.41%\n",
            "Iter: 270 Error: 0.216836 Train Acc: 96.11% Test Acc: 95.47%\n",
            "Iter: 280 Error: 0.216014 Train Acc: 96.11% Test Acc: 95.36%\n",
            "Iter: 290 Error: 0.216606 Train Acc: 96.17% Test Acc: 95.51%\n",
            "Iter: 300 Error: 0.214047 Train Acc: 96.22% Test Acc: 95.52%\n",
            "Iter: 310 Error: 0.214355 Train Acc: 96.23% Test Acc: 95.48%\n",
            "Iter: 320 Error: 0.213518 Train Acc: 96.22% Test Acc: 95.50%\n",
            "Iter: 330 Error: 0.213762 Train Acc: 96.26% Test Acc: 95.59%\n",
            "Iter: 340 Error: 0.212470 Train Acc: 96.32% Test Acc: 95.55%\n",
            "Iter: 349 Error: 0.211379 Train Acc: 96.32% Test Acc: 95.59%\n",
            "Trening zakończony w 815.06s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title L4 - Zadanie 3: Tanh + Softmax\n",
        "# section: main_execution (Zadanie 4.3.3)\n",
        "def run_experiment_advanced(train_size, epochs, alpha, batch_size):\n",
        "    print(\"\\n\" + \"=\"*80)\n",
        "    print(f\"START EKSPERYMENTU (Tanh+Softmax): Train: {train_size}, Alpha: {alpha}\")\n",
        "    print(f\"Params: epochs={epochs}, batch_size={batch_size}, weights=<-0.01, 0.01>\")\n",
        "    print(\"=\"*80)\n",
        "\n",
        "    # Przygotowanie danych\n",
        "    X_train = X_train_all[:train_size]\n",
        "    Y_train = Y_train_all[:train_size]\n",
        "    y_train_labels = y_train_labels_all[:train_size]\n",
        "    X_test = X_test_all\n",
        "    y_test_labels = y_test_labels_all\n",
        "    hidden_size = 100\n",
        "\n",
        "    # Budowa sieci\n",
        "    network = [\n",
        "        Layer(784, hidden_size),\n",
        "        Activation(tanh, tanh_prime),\n",
        "        Layer(hidden_size, 10),\n",
        "        Activation(softmax, softmax_prime)\n",
        "    ]\n",
        "    network[0].weights = np.random.uniform(-0.01, 0.01, (784, hidden_size))\n",
        "    network[2].weights = np.random.uniform(-0.01, 0.01, (hidden_size, 10))\n",
        "\n",
        "    start_time = time.time()\n",
        "    for epoch in range(epochs):\n",
        "        total_error = 0\n",
        "        train_correct = 0\n",
        "        indices = np.arange(train_size)\n",
        "        np.random.shuffle(indices)\n",
        "\n",
        "        for i in range(0, train_size, batch_size):\n",
        "            batch_indices = indices[i:i+batch_size]\n",
        "            x_batch = X_train[batch_indices]\n",
        "            y_batch = Y_train[batch_indices]\n",
        "\n",
        "            # Forward pass\n",
        "            output = x_batch\n",
        "            for layer in network:\n",
        "                output = layer.forward(output)\n",
        "\n",
        "            # Zbieranie statystyk\n",
        "            total_error += np.sum((output - y_batch)**2)\n",
        "            train_correct += np.sum(np.argmax(output, axis=1) == np.argmax(y_batch, axis=1))\n",
        "\n",
        "            # Obliczanie błędu do propagacji\n",
        "            error = (output - y_batch) / batch_size\n",
        "\n",
        "            # Backward pass\n",
        "            error = network[2].backward(error)\n",
        "            error = network[1].backward(error)\n",
        "            error = network[0].backward(error)\n",
        "\n",
        "            # Aktualizacja wag\n",
        "            network[2].adjust(alpha)\n",
        "            network[0].adjust(alpha)\n",
        "\n",
        "        # Ewaluacja i logowanie\n",
        "        if epoch % 10 == 0 or epoch == epochs - 1:\n",
        "            test_correct = 0\n",
        "            for j in range(0, len(X_test), batch_size):\n",
        "                x_test_batch = X_test[j:j+batch_size]\n",
        "                y_test_labels_batch = y_test_labels[j:j+batch_size]\n",
        "                output = x_test_batch\n",
        "                for layer in network:\n",
        "                    output = layer.forward(output)\n",
        "                test_correct += np.sum(np.argmax(output, axis=1) == y_test_labels_batch)\n",
        "\n",
        "            avg_error = total_error / train_size\n",
        "            train_accuracy = (train_correct / train_size) * 100\n",
        "            test_accuracy = (test_correct / len(X_test)) * 100\n",
        "\n",
        "            print(f\"Iter: {epoch:3d} Error: {avg_error:.6f} Train Acc: {train_accuracy:.2f}% Test Acc: {test_accuracy:.2f}%\")\n",
        "\n",
        "    print(f\"Trening zakończony w {time.time() - start_time:.2f}s\")\n",
        "\n",
        "# Uruchomienie eksperymentów z zadania\n",
        "run_experiment_advanced(train_size=1000, epochs=350, alpha=0.02, batch_size=100)\n",
        "run_experiment_advanced(train_size=10000, epochs=350, alpha=0.2, batch_size=100)\n",
        "run_experiment_advanced(train_size=60000, epochs=350, alpha=0.5, batch_size=100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BOmgJec5P9Pm",
        "outputId": "840e9e97-d2f2-42ac-c3fb-7b5a32d11c9b",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "START EKSPERYMENTU (Tanh+Softmax): Train: 1000, Alpha: 0.02\n",
            "Params: epochs=350, batch_size=100, weights=<-0.01, 0.01>\n",
            "================================================================================\n",
            "Iter:   0 Error: 0.899920 Train Acc: 10.10% Test Acc: 13.60%\n",
            "Iter:  10 Error: 0.894566 Train Acc: 43.00% Test Acc: 40.72%\n",
            "Iter:  20 Error: 0.865844 Train Acc: 51.40% Test Acc: 47.71%\n",
            "Iter:  30 Error: 0.742690 Train Acc: 55.60% Test Acc: 52.08%\n",
            "Iter:  40 Error: 0.575852 Train Acc: 63.70% Test Acc: 61.23%\n",
            "Iter:  50 Error: 0.450681 Train Acc: 74.10% Test Acc: 71.64%\n",
            "Iter:  60 Error: 0.362187 Train Acc: 82.10% Test Acc: 76.92%\n",
            "Iter:  70 Error: 0.300872 Train Acc: 84.80% Test Acc: 79.53%\n",
            "Iter:  80 Error: 0.258297 Train Acc: 86.40% Test Acc: 81.08%\n",
            "Iter:  90 Error: 0.227358 Train Acc: 88.00% Test Acc: 82.03%\n",
            "Iter: 100 Error: 0.203398 Train Acc: 88.40% Test Acc: 82.53%\n",
            "Iter: 110 Error: 0.184671 Train Acc: 89.10% Test Acc: 83.37%\n",
            "Iter: 120 Error: 0.169520 Train Acc: 89.60% Test Acc: 83.99%\n",
            "Iter: 130 Error: 0.156695 Train Acc: 90.00% Test Acc: 84.52%\n",
            "Iter: 140 Error: 0.145608 Train Acc: 91.20% Test Acc: 84.72%\n",
            "Iter: 150 Error: 0.136231 Train Acc: 91.60% Test Acc: 85.10%\n",
            "Iter: 160 Error: 0.127655 Train Acc: 92.60% Test Acc: 85.26%\n",
            "Iter: 170 Error: 0.120231 Train Acc: 93.20% Test Acc: 85.56%\n",
            "Iter: 180 Error: 0.113514 Train Acc: 93.50% Test Acc: 85.55%\n",
            "Iter: 190 Error: 0.107238 Train Acc: 93.60% Test Acc: 85.71%\n",
            "Iter: 200 Error: 0.101444 Train Acc: 94.30% Test Acc: 85.90%\n",
            "Iter: 210 Error: 0.096191 Train Acc: 94.90% Test Acc: 86.00%\n",
            "Iter: 220 Error: 0.091434 Train Acc: 95.30% Test Acc: 86.13%\n",
            "Iter: 230 Error: 0.086905 Train Acc: 95.60% Test Acc: 86.20%\n",
            "Iter: 240 Error: 0.082408 Train Acc: 95.80% Test Acc: 86.32%\n",
            "Iter: 250 Error: 0.078493 Train Acc: 96.00% Test Acc: 86.39%\n",
            "Iter: 260 Error: 0.074864 Train Acc: 96.20% Test Acc: 86.41%\n",
            "Iter: 270 Error: 0.071176 Train Acc: 96.50% Test Acc: 86.43%\n",
            "Iter: 280 Error: 0.067664 Train Acc: 96.80% Test Acc: 86.44%\n",
            "Iter: 290 Error: 0.064434 Train Acc: 96.90% Test Acc: 86.50%\n",
            "Iter: 300 Error: 0.061307 Train Acc: 97.10% Test Acc: 86.48%\n",
            "Iter: 310 Error: 0.058343 Train Acc: 97.10% Test Acc: 86.50%\n",
            "Iter: 320 Error: 0.055539 Train Acc: 97.40% Test Acc: 86.53%\n",
            "Iter: 330 Error: 0.052810 Train Acc: 97.50% Test Acc: 86.55%\n",
            "Iter: 340 Error: 0.050213 Train Acc: 97.60% Test Acc: 86.51%\n",
            "Iter: 349 Error: 0.047983 Train Acc: 97.80% Test Acc: 86.51%\n",
            "Trening zakończony w 24.38s\n",
            "\n",
            "================================================================================\n",
            "START EKSPERYMENTU (Tanh+Softmax): Train: 10000, Alpha: 0.2\n",
            "Params: epochs=350, batch_size=100, weights=<-0.01, 0.01>\n",
            "================================================================================\n",
            "Iter:   0 Error: 0.561434 Train Acc: 64.00% Test Acc: 85.39%\n",
            "Iter:  10 Error: 0.075839 Train Acc: 95.07% Test Acc: 92.93%\n",
            "Iter:  20 Error: 0.038461 Train Acc: 97.69% Test Acc: 94.14%\n",
            "Iter:  30 Error: 0.019855 Train Acc: 99.01% Test Acc: 94.43%\n",
            "Iter:  40 Error: 0.009943 Train Acc: 99.59% Test Acc: 94.85%\n",
            "Iter:  50 Error: 0.005215 Train Acc: 99.88% Test Acc: 94.92%\n",
            "Iter:  60 Error: 0.002845 Train Acc: 99.94% Test Acc: 95.01%\n",
            "Iter:  70 Error: 0.001662 Train Acc: 99.97% Test Acc: 95.01%\n",
            "Iter:  80 Error: 0.001012 Train Acc: 99.99% Test Acc: 95.04%\n",
            "Iter:  90 Error: 0.000628 Train Acc: 100.00% Test Acc: 95.01%\n",
            "Iter: 100 Error: 0.000434 Train Acc: 100.00% Test Acc: 95.08%\n",
            "Iter: 110 Error: 0.000318 Train Acc: 100.00% Test Acc: 95.13%\n",
            "Iter: 120 Error: 0.000240 Train Acc: 100.00% Test Acc: 95.21%\n",
            "Iter: 130 Error: 0.000180 Train Acc: 100.00% Test Acc: 95.17%\n",
            "Iter: 140 Error: 0.000141 Train Acc: 100.00% Test Acc: 95.16%\n",
            "Iter: 150 Error: 0.000117 Train Acc: 100.00% Test Acc: 95.19%\n",
            "Iter: 160 Error: 0.000094 Train Acc: 100.00% Test Acc: 95.18%\n",
            "Iter: 170 Error: 0.000079 Train Acc: 100.00% Test Acc: 95.22%\n",
            "Iter: 180 Error: 0.000066 Train Acc: 100.00% Test Acc: 95.16%\n",
            "Iter: 190 Error: 0.000057 Train Acc: 100.00% Test Acc: 95.19%\n",
            "Iter: 200 Error: 0.000049 Train Acc: 100.00% Test Acc: 95.17%\n",
            "Iter: 210 Error: 0.000043 Train Acc: 100.00% Test Acc: 95.17%\n",
            "Iter: 220 Error: 0.000038 Train Acc: 100.00% Test Acc: 95.16%\n",
            "Iter: 230 Error: 0.000033 Train Acc: 100.00% Test Acc: 95.15%\n",
            "Iter: 240 Error: 0.000030 Train Acc: 100.00% Test Acc: 95.18%\n",
            "Iter: 250 Error: 0.000026 Train Acc: 100.00% Test Acc: 95.18%\n",
            "Iter: 260 Error: 0.000024 Train Acc: 100.00% Test Acc: 95.23%\n",
            "Iter: 270 Error: 0.000022 Train Acc: 100.00% Test Acc: 95.21%\n",
            "Iter: 280 Error: 0.000019 Train Acc: 100.00% Test Acc: 95.24%\n",
            "Iter: 290 Error: 0.000018 Train Acc: 100.00% Test Acc: 95.21%\n",
            "Iter: 300 Error: 0.000016 Train Acc: 100.00% Test Acc: 95.19%\n",
            "Iter: 310 Error: 0.000015 Train Acc: 100.00% Test Acc: 95.24%\n",
            "Iter: 320 Error: 0.000014 Train Acc: 100.00% Test Acc: 95.22%\n",
            "Iter: 330 Error: 0.000013 Train Acc: 100.00% Test Acc: 95.19%\n",
            "Iter: 340 Error: 0.000012 Train Acc: 100.00% Test Acc: 95.25%\n",
            "Iter: 349 Error: 0.000011 Train Acc: 100.00% Test Acc: 95.21%\n",
            "Trening zakończony w 186.71s\n",
            "\n",
            "================================================================================\n",
            "START EKSPERYMENTU (Tanh+Softmax): Train: 60000, Alpha: 0.5\n",
            "Params: epochs=350, batch_size=100, weights=<-0.01, 0.01>\n",
            "================================================================================\n",
            "Iter:   0 Error: 0.165667 Train Acc: 88.84% Test Acc: 94.56%\n",
            "Iter:  10 Error: 0.012194 Train Acc: 99.29% Test Acc: 97.73%\n",
            "Iter:  20 Error: 0.001997 Train Acc: 99.94% Test Acc: 97.96%\n",
            "Iter:  30 Error: 0.000382 Train Acc: 100.00% Test Acc: 97.95%\n",
            "Iter:  40 Error: 0.000134 Train Acc: 100.00% Test Acc: 98.01%\n",
            "Iter:  50 Error: 0.000068 Train Acc: 100.00% Test Acc: 98.01%\n",
            "Iter:  60 Error: 0.000040 Train Acc: 100.00% Test Acc: 98.01%\n",
            "Iter:  70 Error: 0.000026 Train Acc: 100.00% Test Acc: 98.00%\n",
            "Iter:  80 Error: 0.000018 Train Acc: 100.00% Test Acc: 97.97%\n",
            "Iter:  90 Error: 0.000013 Train Acc: 100.00% Test Acc: 97.99%\n",
            "Iter: 100 Error: 0.000010 Train Acc: 100.00% Test Acc: 97.97%\n",
            "Iter: 110 Error: 0.000008 Train Acc: 100.00% Test Acc: 98.00%\n",
            "Iter: 120 Error: 0.000006 Train Acc: 100.00% Test Acc: 97.95%\n",
            "Iter: 130 Error: 0.000005 Train Acc: 100.00% Test Acc: 97.97%\n",
            "Iter: 140 Error: 0.000004 Train Acc: 100.00% Test Acc: 97.99%\n",
            "Iter: 150 Error: 0.000004 Train Acc: 100.00% Test Acc: 97.98%\n",
            "Iter: 160 Error: 0.000003 Train Acc: 100.00% Test Acc: 97.98%\n",
            "Iter: 170 Error: 0.000003 Train Acc: 100.00% Test Acc: 97.99%\n",
            "Iter: 180 Error: 0.000002 Train Acc: 100.00% Test Acc: 97.98%\n",
            "Iter: 190 Error: 0.000002 Train Acc: 100.00% Test Acc: 97.97%\n",
            "Iter: 200 Error: 0.000002 Train Acc: 100.00% Test Acc: 97.97%\n",
            "Iter: 210 Error: 0.000002 Train Acc: 100.00% Test Acc: 97.97%\n",
            "Iter: 220 Error: 0.000001 Train Acc: 100.00% Test Acc: 97.99%\n",
            "Iter: 230 Error: 0.000001 Train Acc: 100.00% Test Acc: 97.98%\n",
            "Iter: 240 Error: 0.000001 Train Acc: 100.00% Test Acc: 97.98%\n",
            "Iter: 250 Error: 0.000001 Train Acc: 100.00% Test Acc: 98.00%\n",
            "Iter: 260 Error: 0.000001 Train Acc: 100.00% Test Acc: 98.00%\n",
            "Iter: 270 Error: 0.000001 Train Acc: 100.00% Test Acc: 97.98%\n",
            "Iter: 280 Error: 0.000001 Train Acc: 100.00% Test Acc: 97.99%\n",
            "Iter: 290 Error: 0.000001 Train Acc: 100.00% Test Acc: 97.99%\n",
            "Iter: 300 Error: 0.000001 Train Acc: 100.00% Test Acc: 97.98%\n",
            "Iter: 310 Error: 0.000001 Train Acc: 100.00% Test Acc: 97.99%\n",
            "Iter: 320 Error: 0.000001 Train Acc: 100.00% Test Acc: 98.00%\n",
            "Iter: 330 Error: 0.000001 Train Acc: 100.00% Test Acc: 97.99%\n",
            "Iter: 340 Error: 0.000001 Train Acc: 100.00% Test Acc: 97.99%\n",
            "Iter: 349 Error: 0.000000 Train Acc: 100.00% Test Acc: 97.99%\n",
            "Trening zakończony w 1028.87s\n"
          ]
        }
      ]
    }
  ]
}